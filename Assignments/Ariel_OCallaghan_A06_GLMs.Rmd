---
title: "Assignment 6: GLMs (Linear Regressios, ANOVA, & t-tests)"
author: "Ariel O'Callaghan"
output: pdf_document
geometry: margin=2.54cm
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
#This code chunk will tidy your knit PDF files, wrapping long code lines
#For it to work, the "formatR" package needs to be installed

#install.packages('formatR')
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=50), tidy=TRUE)
```

## OVERVIEW

This exercise accompanies the lessons in Environmental Data Analytics on generalized linear models. 

## Directions
1. Rename this file `<FirstLast>_A06_GLMs.Rmd` (replacing `<FirstLast>` with your first and last name).
2. Change "Student Name" on line 3 (above) with your name.
3. Work through the steps, **creating code and output** that fulfill each instruction.
4. Be sure to **answer the questions** in this assignment document.
5. When you have completed the assignment, **Knit** the text and code into a single PDF file.


## Set up your session 
1. Set up your session. Check your working directory. Load the tidyverse, agricolae and other needed packages. Import the *raw* NTL-LTER raw data file for chemistry/physics (`NTL-LTER_Lake_ChemistryPhysics_Raw.csv`). Set date columns to date objects.

2. Build a ggplot theme and set it as your default theme.

```{r, fig.height = 3, fig.width = 4, warning = FALSE}
#1
getwd()

install.packages('formatR')

install.packages("tidyverse")
install.packages("agricolae")
install.packages("lubridate")
install.packages("corrplot")

library(tidyverse)
library(agricolae)
library(lubridate)
library(corrplot)

NTL.chem.raw <- 
  read.csv("./Data/Raw/NTL-LTER_Lake_ChemistryPhysics_Raw.csv", stringsAsFactors = TRUE)

NTL.chem.raw$sampledate <- as.Date(NTL.chem.raw$sampledate, format = "%m/%d/%y")
class(NTL.chem.raw$sampledate)

#2
mytheme <- theme_classic(base_size = 14) + 
  theme(axis.text = element_text(color = "black"), 
        legend.position = "top")

theme_set(mytheme) #set theme for all subsequent plots 

```

## Simple regression
Our first research question is: Does mean lake temperature recorded during July change with depth across all lakes?

3. State the null and alternative hypotheses for this question:
> Answer:
H0: Lake temerpature does not change with depth during the month of July
Ha: Lake temperature does change with depth during the month of July


4.  Wrangle your NTL-LTER dataset with a pipe function so that the records meet the following criteria: 
 * Only dates in July. 
 * Only the columns: `lakename`, `year4`, `daynum`, `depth`, `temperature_C`
 * Only complete cases (i.e., remove NAs)

5. Visualize the relationship among the two continuous variables with a scatter plot of temperature by depth. Add a smoothed line showing the linear model, and limit temperature values from 0 to 35 Â°C. Make this plot look pretty and easy to read.

```{r scatterplot}
#4

NTL.chem.wrangled <- 
  NTL.chem.raw %>%
  mutate(Month = month(sampledate)) %>%
  filter(Month == 7) %>%
  select(lakename , year4, daynum, depth, temperature_C) %>%
  na.omit()
  
#5

#scatterplot
temp.vs.depth<-
  ggplot(NTL.chem.raw, aes(x = depth, y = temperature_C)) +
   geom_point(alpha= 0.7, size = 2.5) +
  geom_smooth(method = lm, color = "blue") +
  ylim(0, 35)+
  theme(legend.position = "top")+
  labs(x="Depth (Meters)", y= "Temperature (C)")
print(temp.vs.depth)



```
```


6. Interpret the figure. What does it suggest with regards to the response of temperature to depth? Do the distribution of points suggest about anything about the linearity of this trend?

> Answer: As depth increases temperature increases. This shows a negative correclation between temperature and depth. There are also less data points of depths greater then ~8 meters. This could impact the trendline. 


7. Perform a linear regression to test the relationship and display the results

```

```{r}
#7

#regression information 
temp.depth.regression <- lm(NTL.chem.raw$temperature_C ~ NTL.chem.raw$depth)
summary(temp.depth.regression)

#correlation
cor.test(NTL.chem.raw$temperature_C, NTL.chem.raw$depth)


```



8. Interpret your model results in words. Include how much of the variability in temperature is explained by changes in depth, the degrees of freedom on which this finding is based, and the statistical significance of the result. Also mention how much temperature is predicted to change for every 1m change in depth. 

> Answer:
The R-squared value is 0.67 percent which means that 67% of the data is repersented by 34754 degrees of freedom. Also you have a negative correlcation of - 0.81 between temperature and depth. 

---

## Multiple regression
Let's tackle a similar question from a different approach. Here, we want to explore what might the best set of predictors for lake temperature in July across the monitoring period at the North Temperate Lakes LTER. 


9. Run an AIC to determine what set of explanatory variables (year4, daynum, depth) is best suited to predict temperature.

10. Run a multiple regression on the recommended set of variables. 

```{r temperature.model}
#9

TPAIC<- lm(data = NTL.chem.wrangled, temperature_C ~ year4  + daynum + depth)
step(TPAIC)

summary(TPAIC)

#NTL.corr <- cor(NTL.chem.wrangled)
#corrplot(NTL.corr, method = "ellipse")
#corrplot.mixed(NTL.corr, upper = "ellipse")

#10
tempregression <-lm(data = NTL.chem.wrangled, temperature_C ~ year4  + daynum + depth)
summary(tempregression)

variable.regression <- lm(data = NTL.chem.wrangled, temperature_C ~ year4  + daynum)
summary(variable.regression)

variable.regression <- lm(data = NTL.chem.wrangled, temperature_C ~ year4  + daynum + depth)
summary(variable.regression)
```

11. What is the final set of explanatory variables that the AIC method suggests we use to predict temperature in our multiple regression? How much of the observed variance does this model explain? Is this an improvement over the model using only depth as the explanatory variable?

> Answer: 
The R-squared value increased from .67 when just using depth to 0.74 when adding in year4, daynum. A regression run with out depth returns an R squared value of 0.002363. None has the lowest AIC vairable of 26066 so all of the other varialbes will stay in the regression.  


---
## Analysis of Variance

12. Now we want to see whether the different lakes have, on average, different temperatures in the month of July. Run an ANOVA test to complete this analysis. (No need to test assumptions of normality or similar variances.) Create two sets of models: one expressed as an ANOVA models and another expressed as a linear model (as done in our lessons).

```{r anova.model}
#12

# Do not use # bartlett.test(NTL.chem.wrangled$lakename ~NTL.chem.wrangled$temperature_C)

anova.lakes <- aov(data = NTL.chem.wrangled, temperature_C ~ lakename)
summary(anova.lakes)


anova.lakes.lm <- lm(data = NTL.chem.wrangled, temperature_C ~ lakename)
summary(anova.lakes.lm)


```

13. Is there a significant difference in mean temperature among the lakes? Report your findings. 

> Answer: The Anova model shows that mean temperature among all the lakes to be statistically
signicant. The linear model shows how statistically different every single lake is by providing a their specific p-values. The estimated standard delivation from the intercept is different from intecept temberapture.  The standard error value on th linear model is 7.355.


14. Create a graph that depicts temperature by depth, with a separate color for each lake. Add a geom_smooth (method = "lm", se = FALSE) for each lake. Make your points 50 % transparent. Adjust your y axis limits to go from 0 to 35 degrees. Clean up your graph to make it pretty. 

```{r scatterplot.2}
#14.
temp.depth.3 <-
  ggplot(NTL.chem.wrangled, aes(x= depth, y= temperature_C, color= lakename))+
  geom_point(alpha= 0.5, size = 2.5)+
  geom_smooth(method = lm, se = FALSE) +
  ylim(0,35)+ 
  labs(x="Temperature (c)", y="Depth (ft)") +
  theme(legend.position = "top", 
        legend.text = element_text(size = 12), legend.title = element_text(size = 12))
print(temp.depth.3)

```

15. Use the Tukey's HSD test to determine which lakes have different means.

```{r tukey.test}
#15

TukeyHSD(anova.lakes)

anova.lakes.hsd <- HSD.test(anova.lakes, "lakename", group = TRUE)
anova.lakes.hsd

summary.aov(anova.lakes)
```

16.From the findings above, which lakes have the same mean temperature, statistically speaking, as Peter Lake? Does any lake have a mean temperature that is statistically distinct from all the other lakes?

>Answer:
The Anova test does not idenfiy particular differences between paris of means are significant. This Tukey Honest Significant Differerences method determines. Peter and Paul lake both have c grouping and similar means. Peter and paul lake are statistically sginfication with means temp of 13.31 and 13.81 respectively. Ward Lake-Crampton Lake have a difference in mean temperature of 0.8932661 
 

17. If we were just looking at Peter Lake and Paul Lake. What's another test we might explore to see whether they have distinct mean temperatures? 

>Answer: We could run a two sample T test on peter and paul lake. 



18. Wrangle the July data to include only records for Crampton Lake and Ward Lake. Run the two-sample T-test on these data to determine whether their July temperature are same or different. What does the test say? Are the mean temperatures for the lakes equal? Does that match you answer for part 16?

```{r t.test}
#Ho Mu>=50
#Ha mu<50

crampton.ward.lake<-
  NTL.chem.wrangled %>%
  filter(lakename == c("Crampton Lake", "Ward Lake"))

summary(crampton.ward.lake)
length(crampton.ward.lake)

crampton.ward.ttest <- t.test(crampton.ward.lake$temperature_C, mu=50, alternative = "less")
crampton.ward.ttest

ttest2 <- t.test(crampton.ward.lake$temperature_C ~ crampton.ward.lake$lakename)
ttest2
```

>Answer:  There are 214 degrees of freedom or obervations. The p value is 0.5 so we are rejecting the null hypothesis and accepting the alternative hypotheis. The means of Crampton lake is 15.37 and the mean of Ward Lake is 14.25. 
